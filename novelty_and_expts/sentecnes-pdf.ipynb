{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9830470,"sourceType":"datasetVersion","datasetId":6029118}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import TrOCRProcessor, VisionEncoderDecoderModel\nfrom PIL import Image\n\n# Initialize the processor and model\nprocessor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-handwritten\")\nmodel = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-handwritten\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-07T06:06:29.297466Z","iopub.execute_input":"2024-11-07T06:06:29.297985Z","iopub.status.idle":"2024-11-07T06:07:24.060653Z","shell.execute_reply.started":"2024-11-07T06:06:29.297911Z","shell.execute_reply":"2024-11-07T06:07:24.059477Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f67e71c575249c8ad9e0f257b0d6658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91e7ac663384fb0b7e4ae8458050419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"378e1340d118469bbaadc659178dff35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae43a531d2145949a46b4b9540a4d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e3faa3703b04284b34b789d5ee0ff8b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ae976c38804d61bc473e488de185f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9df30c3efae440ea891629a31d16627"}},"metadata":{}},{"name":"stderr","text":"VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\nSome weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbb7e7970f24b8ca13898bab041c126"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# Specify the path to your local image\nimage_path = r'/kaggle/input/qwertyuiop/r03-030-s00-00.png' # Replace with your actual image path\n\n# Load the image from the local file system\ntry:\n    image = Image.open(image_path).convert(\"RGB\")\nexcept FileNotFoundError:\n    print(f\"Error: The file at {image_path} was not found.\")\n    exit(1)\n\n# Process the image and generate text\npixel_values = processor(image, return_tensors=\"pt\").pixel_values\ngenerated_ids = model.generate(pixel_values)\n\n# Decode the generated text\ngenerated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\nprint(\"Generated Text:\")\nprint(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T06:07:48.558377Z","iopub.execute_input":"2024-11-07T06:07:48.559306Z","iopub.status.idle":"2024-11-07T06:07:56.724684Z","shell.execute_reply.started":"2024-11-07T06:07:48.559258Z","shell.execute_reply":"2024-11-07T06:07:56.723545Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Generated Text:\nThe next thing that Serena discovered was that\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install sympy\n!pip install language-tool-python\n!pip install reportlab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T06:07:56.726611Z","iopub.execute_input":"2024-11-07T06:07:56.727061Z","iopub.status.idle":"2024-11-07T06:08:40.905253Z","shell.execute_reply.started":"2024-11-07T06:07:56.727003Z","shell.execute_reply":"2024-11-07T06:08:40.903521Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (1.12)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy) (1.3.0)\nCollecting language-tool-python\n  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (24.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (4.66.4)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from language-tool-python) (0.43.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->language-tool-python) (2024.8.30)\nDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\nInstalling collected packages: language-tool-python\nSuccessfully installed language-tool-python-2.8.1\nCollecting reportlab\n  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from reportlab) (10.3.0)\nCollecting chardet (from reportlab)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nDownloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: chardet, reportlab\nSuccessfully installed chardet-5.2.0 reportlab-4.2.5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import re\nimport sympy as sp\nimport language_tool_python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\nfrom reportlab.lib.units import inch\n\n# Function to extract LaTeX math and convert it into text\ndef latex_to_text(latex_str):\n    # Use sympy to parse LaTeX for math expressions\n    try:\n        expr = sp.sympify(latex_str)\n        return str(expr)\n    except (sp.SympifyError, ValueError):\n        # If parsing fails, return the original LaTeX as text\n        return latex_str\n\n# Function to correct grammar using LanguageTool\ndef correct_grammar(text):\n    tool = language_tool_python.LanguageTool('en-US')  # Set the language\n    matches = tool.check(text)\n    corrected_text = language_tool_python.utils.correct(text, matches)\n    return corrected_text\n\n# Function to convert text to a PDF file\ndef text_to_pdf(text, output_pdf):\n    c = canvas.Canvas(output_pdf, pagesize=letter)\n    width, height = letter\n    # Splitting text into multiple lines for PDF (line wrap)\n    lines = text.split('\\n')\n    y = height - 40  # Top margin\n\n    for line in lines:\n        if y < 40:  # Bottom margin, start a new page\n            c.showPage()\n            y = height - 40\n\n        # Add LaTeX rendering logic\n        if '$' in line or '\\\\[' in line:  # Check if line contains LaTeX math\n            # Render LaTeX here using a method of your choice\n            c.drawString(40, y, line)  # This won't render math; requires more work\n        else:\n            c.drawString(40, y, line)\n        y -= 15  # Line spacing\n\n    c.save()\n\n# Main function\ndef process_latex_input(latex_text, output_pdf):\n    # Find all LaTeX math enclosed in $...$ or \\[...\\]\n    latex_math = re.findall(r'\\$[^\\$]*\\$|\\\\\\[.*?\\\\\\]', latex_text)\n\n    # Replace LaTeX math with plain text equivalents\n    for math_expr in latex_math:\n        plain_text = latex_to_text(math_expr.strip('$').strip('\\\\[').strip('\\\\]'))\n        latex_text = latex_text.replace(math_expr, plain_text)\n\n    # Correct the grammar of the text\n    corrected_text = correct_grammar(latex_text)\n\n    # Convert the corrected text to a PDF\n    text_to_pdf(corrected_text, output_pdf)\n    print(f\"PDF generated at: {output_pdf}\")\n\n# Example usage\n# process_latex_input(\"Here is some math: $E=mc^2$ and here is text.\", \"output.pdf\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T06:08:40.908331Z","iopub.execute_input":"2024-11-07T06:08:40.908864Z","iopub.status.idle":"2024-11-07T06:08:41.008266Z","shell.execute_reply.started":"2024-11-07T06:08:40.908790Z","shell.execute_reply":"2024-11-07T06:08:41.007088Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# # Example usage\n# latex_input = \"\"\"This is an example. The equation is $x^2 + y^2 = z^2$.\n# We also have the integral $ \\int_0^1 x^2 dx $.\"\"\"\noutput_pdf_path = \"outputtt.pdf\"\n\n# Process the LaTeX input and generate the PDF\nprocess_latex_input(generated_text, output_pdf_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T06:14:49.595096Z","iopub.execute_input":"2024-11-07T06:14:49.595615Z","iopub.status.idle":"2024-11-07T06:15:18.499504Z","shell.execute_reply.started":"2024-11-07T06:14:49.595566Z","shell.execute_reply":"2024-11-07T06:15:18.498158Z"}},"outputs":[{"name":"stdout","text":"PDF generated at: outputtt.pdf\n","output_type":"stream"}],"execution_count":12}]}